defaults:
  - model: mistral_7b
  - dataset: anthropic_hh_rlhf
  - trainer: dpo
  - _self_

seed: 42
wandb:
  project: resource_efficient_sft_dpo
  run_name: dpo-single-gpu
