# Resource-Efficient LLM Fine-Tuning with Alignment

This project provides scripts, configs, and notebooks for **resource-efficient fine-tuning of large language models (LLMs)** using:
- **Supervised Fine-Tuning (SFT)**
- **Direct Preference Optimization (DPO)**
- **DeepSpeed** for memory-efficient training

## ðŸ“‚ Project Structure
- `train_sft.py` â€“ run supervised fine-tuning
- `train_dpo.py` â€“ run preference optimization
- `custom_dpo.py` â€“ custom DPO trainer implementation
- `configs/` â€“ YAML/JSON configs for datasets, models, trainers, and DeepSpeed
- `sagemaker/` â€“ example notebooks for running SFT & DPO on AWS SageMaker
- `requirements.txt` â€“ dependencies

## ðŸš€ Quick Start
Install dependencies:
```bash
pip install -r requirements.txt
```

Run SFT:
```bash
python train_sft.py
```

Run DPO:
```bash
python train_dpo.py
```
